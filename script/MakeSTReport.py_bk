import cv2
import os
import h5py
import json
import argparse
import tifffile
import numpy as np
import pandas as pd
import scanpy as sc
from pathlib import Path
import matplotlib.pyplot as plt
from collections import defaultdict

parser = argparse.ArgumentParser()
parser.add_argument('--AnalysisDir',help='Analysis Directory',required=True)
parser.add_argument('--Sample',help="Sample Name",required=True)
parser.add_argument('--SoftHome',help="Software Analysis Directory;default:/disk/pipeline/DynamicST",default="/disk/pipeline/DynamicST")
args = parser.parse_args()


def Spot_and_sequencing_summary(STARSummary):
    summary = {"Spot":{},"sequencing":{}}
    df = pd.read_csv(STARSummary,index_col=0,header=None)
    df.index = df.index.str.replace("Cells","Spots").str.replace("Cell","Spot")
    df = df.dropna()
    df.columns=['index']
    d = df.to_dict()['index']
    summary['sequencing']["Reads Mapped to Genome"] = f"{d['Reads Mapped to Genome: Unique+Multiple']:.2%}"
    summary['sequencing']['Number of Reads'] = f"{int(d['Number of Reads']):,}"
    summary['sequencing']['Valid Barcodes'] = f"{d['Reads With Valid Barcodes']:.2%}"
    summary['sequencing']['Sequencing Saturation'] = f"{d['Sequencing Saturation']:.2%}"
    summary['sequencing']['UMIs in Spots'] = f"{d['UMIs in Spots']:.0f}"
    if d.get('Q30 Bases in CB+UMI'):
        summary['sequencing']['CB+UMI'] = f"""
<tr>
  <th>Q30 Bases in CB+UMI</th>
  <th>{d['Q30 Bases in CB+UMI']:.2%}</th>
</tr>
"""
    else:
        summary['sequencing']['CB+UMI'] = ""
    summary['sequencing']['Q30 Bases in RNA Read'] = f"{d['Q30 Bases in RNA read']:.2%}"
    summary['Spot']['Estimated Number of Spots'] = f"{int(d['Estimated Number of Spots']):,}"
    summary['Spot']['Fraction Reads in Spots'] = f"{d['Fraction of Unique Reads in Spots']:.2%}"
    summary['Spot']['Mean Reads per Spot'] = f"{int(int(d['Number of Reads'])/int(d['Estimated Number of Spots'])):,}"
    summary['Spot']['Median UMI Counts per Spot'] = f"{int(d['Median UMI per Spot']):,}"

    if 'Median Gene per Spot' in d:
        summary['Spot']['Median Genes per Spot'] = f"{int(d['Median Gene per Spot']):,}"
        summary['Spot']['Total Genes Detected'] = f"{int(d['Total Gene Detected']):,}"
    else:
        summary['Spot']['Median Genes per Spot'] = f"{int(d['Median GeneFull per Spot']):,}"
        summary['Spot']['Total Genes Detected'] = f"{int(d['Total GeneFull Detected']):,}"

    return summary



def mapping_summary(STARLog, RnaSeqMetrics):
    d={}
    summary = {}
    with open(STARLog, 'r',encoding='utf-8') as fh:
        for line in fh:
            if 'Number of input reads' in line:
                summary['Number of input reads'] = int(
                    line.strip().split('\t')[-1])
            if 'Uniquely mapped reads number' in line:
                summary['Uniquely mapped reads number'] = int(
                    line.strip().split('\t')[-1])
            if 'Number of reads mapped to multiple loci' in line:
                summary['Number of reads mapped to multiple loci'] = int(
                    line.strip().split('\t')[-1])
    with open(RnaSeqMetrics, 'r',encoding='utf-8') as fh:
        while True:
            line = fh.readline().strip()
            if line.startswith('total alignments'):
                summary['total alignments'] = int(line.split()[-1].replace(
                    ',', ''))
            if line.startswith('reads aligned'):
                summary['reads aligned'] = int(line.split()[-1].replace(
                    ',', ''))
            if line.startswith('aligned to genes'):
                summary['aligned to genes'] = int(line.split()[-1].replace(
                    ',', ''))
            if line.startswith('no feature assigned'):
                summary['no feature assigned'] = int(line.split()[-1].replace(
                    ',', ''))
            if line.startswith('exonic'):
                summary['exonic'] = int(line.split()[-2].replace(',', ''))
            if line.startswith('intronic'):
                summary['intronic'] = int(line.split()[-2].replace(',', ''))
            if line.startswith('intergenic'):
                summary['intergenic'] = int(line.split()[-2].replace(',', ''))
                break
    #d['Reads Mapped to Genome'] = f"{summary['reads aligned']/summary['Number of input reads']:.2%}"
    intergenic = summary['intergenic']/summary['Number of input reads']
    intronic = summary['intronic']/summary['Number of input reads']
    exonic = summary['exonic']/summary['Number of input reads']
    d['Reads Mapped Confidently to Genome'] = f"{intergenic+intronic+exonic:.2%}"
    d['Reads Mapped Confidently to Intergenic Regions'] = f"{intergenic:.2%}"
    d['Reads Mapped Confidently to Intronic Regions'] = f"{intronic:.2%}"
    d['Reads Mapped Confidently to Exonic Regions'] = f"{exonic:.2%}"
    return d

def Sample_summary(config):
    summary = {}
    d = json.load(open(config))
    summary['Sample ID'] = d['sample']
    summary['Sample Description'] = d.get("Sample Description","")
    summary['Chemistry'] = "Single Spot 3' v1"
    summary['Include introns'] = "False"
    summary['Transcriptome'] = Path(d['transcriptome']).parent.name
    summary['Pipeline Version'] = "DynamicST-1.0.0"
    return summary
    
def fastp_qc(fastp):
    summary={}
    d = json.load(open(fastp))
    summary["gc_content"] = f"{d['summary']['before_filtering']['gc_content']:.2%}"
    summary["too_short_reads"] = f"{d['filtering_result']['too_short_reads']:,}"
    summary["too_many_N_reads"] = f"{d['filtering_result']['too_many_N_reads']:,}"
    summary['q20_rate'] = f"{d['summary']['before_filtering']['q20_rate']:.2%}"
    return summary

def GetCoord(img):
    img = cv2.imread(img)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    stepx = img.shape[0]/51
    stepy = img.shape[1]/51
    xcoord = []
    ycoord = []
    for x in range(1,51):
        for y in range(1,51):
            xcoord.append(x*stepx)
            ycoord.append(y*stepy)
    return img,xcoord,ycoord

def SpotsPlot(img,df):
    plt.figure(figsize=(14,14))
    plt.imshow(img)
    dt = df[df['in_tissue'] == 1]
    for y,x in dt[['pxl_col_in_fullres','pxl_row_in_fullres']].values:
        plt.scatter(x,y,color='red',s=40,marker='s',lw=0.4,edgecolors='black')
    plt.axis("off")
    Path(f"{AnalysisDir}/{sample}/outs/src").mkdir(exist_ok=True,parents=True)
    plt.savefig(f"{AnalysisDir}/{sample}/outs/src/Spots.png")

def MakeSpatial(img):
    try:
        barcode = pd.read_csv(str(AnalysisDir/f"{sample}/outs/filtered_feature_bc_matrix/barcodes.tsv.gz"),sep='\t',header=None)
    except:
        barcode = pd.read_csv(str(AnalysisDir/f"{sample}/outs/filtered_feature_bc_matrix/barcodes.tsv"),sep='\t',header=None)
    tissue = list(barcode[0].values)

    img,xcoord,ycoord = GetCoord(img)
    df = pd.read_csv(str(SoftHome/'db/barcode_coordinate.txt'),sep='\t',index_col=0)
    df["pxl_col_in_fullres"] = ycoord
    df["pxl_row_in_fullres"] = xcoord
    df['in_tissue'] = [0 if b not in tissue else 1 for b in df.index]
    SpotsPlot(img,df)
    Path(f"{AnalysisDir}/{sample}/outs/spatial").mkdir(exist_ok=True,parents=True)
    df = df[['in_tissue','y','x','pxl_col_in_fullres','pxl_row_in_fullres']]
    df.to_csv(f"{AnalysisDir}/{sample}/outs/spatial/tissue_positions_list.csv",header=None)
    spot_diameter = df['pxl_col_in_fullres'].values[1] - df['pxl_col_in_fullres'].values[0]
    d={"tissue_hires_scalef":2000/6000,
    "tissue_lowres_scalef":600/6000,
    "fiducial_diameter_fullres":spot_diameter+30,
    "spot_diameter_fullres":spot_diameter}
    with open(f"{AnalysisDir}/{sample}/outs/spatial/scalefactors_json.json","w") as out:
        json.dump(d,out)
    hires_img = cv2.resize(img,(2000,2000))
    lowres_img = cv2.resize(img,(600,600))
    cv2.imwrite(f"{AnalysisDir}/{sample}/outs/spatial/tissue_hires_image.png",hires_img)
    cv2.imwrite(f"{AnalysisDir}/{sample}/outs/spatial/tissue_lowres_image.png",lowres_img)


def MakeH5File(genome):
    f = h5py.File(f"{AnalysisDir}/{sample}/outs/filtered_feature_bc_matrix.h5", "w")
    f.attrs['library_ids'] = np.array([f'{sample}'],dtype="|S27")
    matrix = f.create_group("matrix")
    try:
        barcode = pd.read_csv(f"{AnalysisDir}/{sample}/outs/filtered_feature_bc_matrix/barcodes.tsv.gz",sep="\t",header=None)[0].values
    except:
        barcode = pd.read_csv(f"{AnalysisDir}/{sample}/outs/filtered_feature_bc_matrix/barcodes.tsv",sep="\t",header=None)[0].values
    matrix.create_dataset("barcodes", data=barcode)
    try:
        df_mtx = pd.read_csv(f"{AnalysisDir}/{sample}/outs/filtered_feature_bc_matrix/matrix.mtx.gz",sep="\s+",header=None,skiprows=3)
    except:
        df_mtx = pd.read_csv(f"{AnalysisDir}/{sample}/outs/filtered_feature_bc_matrix/matrix.mtx",sep="\s+",header=None,skiprows=3)
    df_mtx[0] = df_mtx[0] - 1
    data = df_mtx[2].values
    matrix.create_dataset("data", data=data)
    features = matrix.create_group("features")
    try:
        df_features = pd.read_csv(f"./{sample}/outs/filtered_feature_bc_matrix/features.tsv.gz",header=None,sep='\t')
    except:
        df_features = pd.read_csv(f"./{sample}/outs/filtered_feature_bc_matrix/features.tsv",header=None,sep='\t')

    features.create_dataset("_all_tag_keys", data=[b'genome'])
    features.create_dataset("feature_type", data=df_features[2].values)
    features.create_dataset("genome", data=[genome]*len(df_features))
    features.create_dataset("id", data=df_features[0].values)
    features.create_dataset("name",data=df_features[1].values)
    indices = df_mtx[0].values
    matrix.create_dataset("indices", data=indices)
    indptr = np.array([0]+list(df_mtx[1].value_counts().sort_index().cumsum().values))
    matrix.create_dataset("indptr", data=indptr)
    shape = np.array([len(df_features),len(df_mtx[1].unique())])
    matrix.create_dataset("shape", data=shape)
    f.close()


AnalysisDir   = Path(args.AnalysisDir)
SoftHome      = Path(args.SoftHome)
sample        = args.Sample
img           = str(AnalysisDir/'image/HEadj.tif')
STARLog       = str(AnalysisDir/"Log.final.out")
RnaSeqMetrics = str(AnalysisDir/"qual_summary/rnaseq_qc_results.txt")
saturation = str(AnalysisDir/"saturation.csv")
sampleinfo    = str(AnalysisDir/"config.json")
STARSummary   = str(AnalysisDir/f"{sample}/Gene/Summary.csv")
output        = str(AnalysisDir/f"{sample}/outs/web_summary.html")
Temp          = str(SoftHome/'template/WPSQCReport_temp.html')
fastp         = str(AnalysisDir/"fastp.json")
MetricsSummary = str(AnalysisDir/sample/'outs/metrics_summary.csv')

genome = Path(json.load(open(sampleinfo,encoding='utf-8'))['transcriptome']).parent.name

MakeSpatial(img)
MakeH5File(genome)

total_summary = {}
total_summary["qc"] = fastp_qc(fastp)
total_summary.update(Spot_and_sequencing_summary(STARSummary))
total_summary['mapping'] = mapping_summary(STARLog, RnaSeqMetrics)
total_summary['sample'] = Sample_summary(sampleinfo)
saturation = list(pd.read_csv(saturation,index_col=0).index)[-1]
total_summary['sequencing']['Sequencing Saturation'] = f"{saturation:.2%}"

metrics_summary = []

ms = {}
for key in total_summary:
    ms.update(total_summary[key])
trans = {"GC Content":"gc_content","Q20 Bases in RNA Read":"q20_rate"}
print(ms)
for key in ["Number of Reads","Valid Barcodes","Sequencing Saturation","GC Content","Q20 Bases in RNA Read","Q30 Bases in RNA Read","Estimated Number of Spots","Fraction Reads in Spots","UMIs in Spots","Mean Reads per Spot","Median UMI Counts per Spot","Median Genes per Spot","Total Genes Detected","Reads Mapped to Genome","Reads Mapped Confidently to Genome","Reads Mapped Confidently to Intergenic Regions","Reads Mapped Confidently to Intronic Regions","Reads Mapped Confidently to Exonic Regions"]:
    key2 = trans.get(key,key)
    metrics_summary.append([key,str(ms[key2]).replace(',','')])
print(pd.DataFrame(metrics_summary))
pd.DataFrame(metrics_summary).T.to_csv(MetricsSummary,index=False,header=False)



f = open(Temp,encoding='utf-8').read()
for key in total_summary:
    for info in total_summary[key]:
        f = f.replace(f"$${info}$$",str(total_summary[key][info]))
        
with open(output,"w",encoding='utf-8') as out:
    out.write(f)
os.system(f"cp -r {SoftHome}/template/static {AnalysisDir}/{sample}/outs")

